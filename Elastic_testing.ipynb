{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "from text_processing.text_preprocessing import df_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter columns from a dfrow that has been converted into a geneartor \n",
    "def filterKeys(document_gen,vars2use):\n",
    "    return {key:document_gen[key] for key in vars2use}\n",
    "\n",
    "#generate douments in elastic format \n",
    "#yeild is used to allow the function to hand off records to Elastic API only when it asks for them \n",
    "def doc_generator(df,index_name, docIdVar, vars2use = None):\n",
    "    \"\"\"\n",
    "    Overview: \n",
    "        provide a dict with specified values to elastic bulk api \n",
    "\n",
    "    Inputs: \n",
    "        df : dataframe to push to elastic \n",
    "        index_name: name of index you want to push data to (database)\n",
    "        docIdVar : id variable in input dataframe \n",
    "        vars2use : list of variables from input df we want to push to elastic \n",
    "    \n",
    "    Yield parameters:\n",
    "        _index: the database name\n",
    "        _type: the table name (this is now _doc for 7.1 and cannot be any other value) \n",
    "        _id: elastic unique ID (not the same as 'id' field from df)\n",
    "        _source: the document to be saved (you could also simply use document.to_dit())\n",
    "        raise StopIteration: raise exception when generator is empty\n",
    "    \"\"\"\n",
    "\n",
    "    df_iter = df.iterrows()\n",
    "    for index, document in df_iter:\n",
    "        yield {\n",
    "                \"_index\": index_name,\n",
    "                \"_type\": \"_doc\",\n",
    "                \"_id\" : f\"{document[docIdVar]+str(index)}\",\n",
    "                \"_source\": filterKeys(document,vars2use),\n",
    "            }\n",
    "    raise StopIteration\n",
    "    \n",
    "#QUERY OPS\n",
    "def search(es_object, index_name, search):\n",
    "    res = es_object.search(index=index_name, body=search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 1: Load df to push to index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"C:\\\\Users\\\\zjc10\\\\Desktop\\\\Projects\\\\data\\\\news\\\\webhose_news\\\\webhose_df.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['key', 'date', 'title', 'author', 'link', 'text'], dtype='object')"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2: MISSING DATA CHECK (ELASTIC CANNOT HANDLE NAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "if df.isnull().sum().sum() > 0:\n",
    "    print(\"STOP AND FIX MISSING DATA\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Push docs to elastic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-2ecefe6a2176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mes_client\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mElasticsearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhttp_compress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mvars2use\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'key'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'date'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'title'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'author'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mhelpers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mes_client\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdoc_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"webhose\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"key\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvars2use\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvars2use\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\zjc10\\desktop\\projects\\envs\\dev\\lib\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36mbulk\u001b[1;34m(client, actions, stats_only, *args, **kwargs)\u001b[0m\n\u001b[0;32m    298\u001b[0m     \u001b[1;31m# make streaming_bulk yield successful results so we can count them\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"yield_ok\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mok\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstreaming_bulk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    301\u001b[0m         \u001b[1;31m# go through request-response pairs and detect failures\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zjc10\\desktop\\projects\\envs\\dev\\lib\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36mstreaming_bulk\u001b[1;34m(client, actions, chunk_size, max_chunk_bytes, raise_on_error, expand_action_callback, raise_on_exception, max_retries, initial_backoff, max_backoff, yield_ok, *args, **kwargs)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     for bulk_data, bulk_actions in _chunk_actions(\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mactions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_chunk_bytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransport\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserializer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     ):\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zjc10\\desktop\\projects\\envs\\dev\\lib\\site-packages\\elasticsearch\\helpers\\actions.py\u001b[0m in \u001b[0;36m_chunk_actions\u001b[1;34m(actions, chunk_size, max_chunk_bytes, serializer)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[0mbulk_actions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbulk_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[0mraw_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mserializer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-42-54de08cd9265>\u001b[0m in \u001b[0;36mdoc_generator\u001b[1;34m(df, index_name, docIdVar, vars2use)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mdf_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocument\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m         yield {\n\u001b[0;32m     29\u001b[0m                 \u001b[1;34m\"_index\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zjc10\\desktop\\projects\\envs\\dev\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36miterrows\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[0mklass\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor_sliced\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m             \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\zjc10\\desktop\\projects\\envs\\dev\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m                 \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es_client = Elasticsearch(http_compress=True)\n",
    "vars2use = ['key','date','title','author']\n",
    "helpers.bulk(es_client,doc_generator(df, \"webhose\",\"key\",vars2use=vars2use))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query Operations though Python\n",
    "\n",
    "##### search results contain following metadata (that is useful)\n",
    " - max_score: the score of the most relevant document found \n",
    " -  hits.total.value: how many matching documents were found \n",
    " -  hits._score: the documents relevance score (not applicable when using match_all)\n",
    " \n",
    "#### boosting within match query \n",
    " - individual fields can be boosted with the caret ^ notation (ex. \"fields\":['title^2','author'])\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 4,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 10000, 'relation': 'gte'},\n",
       "  'max_score': 29.519335,\n",
       "  'hits': [{'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '6726f5aeab38ecfe8ab1aba7db6f8a12c5e3cc860',\n",
       "    '_score': 29.519335,\n",
       "    '_source': {'key': '6726f5aeab38ecfe8ab1aba7db6f8a12c5e3cc86',\n",
       "     'date': '2017-03-25T01:09:00.000+03:00',\n",
       "     'title': 'I hate Fridays in Lent..',\n",
       "     'author': 'Billybob (noreply@blogger.com)'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '7af3f8186071961cf9b599678280e03c9221f5f00',\n",
       "    '_score': 29.519335,\n",
       "    '_source': {'key': '7af3f8186071961cf9b599678280e03c9221f5f0',\n",
       "     'date': '2017-03-13T04:54:00.000+02:00',\n",
       "     'title': 'I hate this planet and ..',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '8a7c9188b4f827147e5fa8f389eab6d6413eb14e0',\n",
       "    '_score': 28.098354,\n",
       "    '_source': {'key': '8a7c9188b4f827147e5fa8f389eab6d6413eb14e',\n",
       "     'date': '2017-03-09T03:36:00.000+02:00',\n",
       "     'title': '10 Things I Hate About Meat',\n",
       "     'author': 'Joe Loria'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'cb00d58ab2789db2eaa3d858ee96a99d448670ed0',\n",
       "    '_score': 26.102133,\n",
       "    '_source': {'key': 'cb00d58ab2789db2eaa3d858ee96a99d448670ed',\n",
       "     'date': '2017-03-11T11:41:00.000+02:00',\n",
       "     'title': 'I can not explain in words how I hate this world',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'a225cd19126079c6a90c06fc3be9a1b4670ef51f0',\n",
       "    '_score': 23.5616,\n",
       "    '_source': {'key': 'a225cd19126079c6a90c06fc3be9a1b4670ef51f',\n",
       "     'date': '2017-03-21T03:15:00.000+02:00',\n",
       "     'title': \"FBI director James Comey: 'I hate the New England Patriots'\",\n",
       "     'author': 'Jay Busbee'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'b62013b555ffdd2ad018fe28be1a1cacd09729480',\n",
       "    '_score': 23.5616,\n",
       "    '_source': {'key': 'b62013b555ffdd2ad018fe28be1a1cacd0972948',\n",
       "     'date': '2017-03-21T03:15:00.000+02:00',\n",
       "     'title': \"FBI director James Comey: 'I hate the New England Patriots'\",\n",
       "     'author': 'Shutdown Corner'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'b26b0ba725ecd2522a8e22b23e57595b9ead60300',\n",
       "    '_score': 23.5616,\n",
       "    '_source': {'key': 'b26b0ba725ecd2522a8e22b23e57595b9ead6030',\n",
       "     'date': '2017-03-28T01:23:00.000+03:00',\n",
       "     'title': 'I cant tell if they love me or hate me',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'f10352387841eaf27a97483da5e36d7deefc762b0',\n",
       "    '_score': 22.751244,\n",
       "    '_source': {'key': 'f10352387841eaf27a97483da5e36d7deefc762b',\n",
       "     'date': '2017-03-25T16:29:00.000+03:00',\n",
       "     'title': 'When is hate not hate?',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '878d489fffc1e0415a8b7e7226f5ee98d81338de0',\n",
       "    '_score': 21.378143,\n",
       "    '_source': {'key': '878d489fffc1e0415a8b7e7226f5ee98d81338de',\n",
       "     'date': '2017-03-06T17:44:00.000+02:00',\n",
       "     'title': '\"Fake Hate Crimes--And Fake Hate, Too\"',\n",
       "     'author': 'Craig'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'b5e7e205e7f965a3dbd44e15731fd751d56b47a30',\n",
       "    '_score': 19.92917,\n",
       "    '_source': {'key': 'b5e7e205e7f965a3dbd44e15731fd751d56b47a3',\n",
       "     'date': '2017-03-09T02:54:00.000+02:00',\n",
       "     'title': 'Heart of Hate',\n",
       "     'author': 'CHIBIMUN &co (noreply@blogger.com)'}}]}}"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = Elasticsearch([{'host': 'localhost', 'port': 9200}])\n",
    "\n",
    "#all titles containing Nintendo in them (from oldest to newest)\n",
    "#something funky going on with date, check out how it is hashed (is it a date field or string)\n",
    "match_response = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\n",
    "            'match': {'title':'Nintendo'},\n",
    "        },\n",
    "    },\n",
    "    sort={\n",
    "        'date': 'desc',\n",
    "    },\n",
    ")\n",
    "\n",
    "#zero term query \n",
    "#auto_generate_synonyms_phrase_query (defaults to true)\n",
    "zeroterm_response = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\n",
    "            'match': {\n",
    "                'title':{\n",
    "                    \"query\":'Launch ny',\n",
    "                    'operator':\"and\",\n",
    "                    'zero_terms_query':'all',\n",
    "                     \"auto_generate_synonyms_phrase_query\" : True,\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    ")\n",
    "\n",
    "\n",
    "#fuzzy results ranked by relevance score (so if it only contains 1 of the 2 words, it will be lower in results)\n",
    "#auto_generate_synonyms_phrase_query (defaults to true)\n",
    "fuzzy_response = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {'match':\n",
    "                  {'title':{\n",
    "                    \"query\":'Launch ny'\n",
    "                    ,\"fuzziness\":2\n",
    "                    },\n",
    "                },\n",
    "            },\n",
    "        },\n",
    ")\n",
    "\n",
    "#multi-match queries \n",
    "#allows multi-field queries \n",
    "mm_results = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\"multi_match\":{\n",
    "                  \"query\": \"i hate amazon\",\n",
    "                  \"fields\":['title^2','author']\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    ")\n",
    "\n",
    "#bool queries \n",
    "#match_bool_prefix(matches terms in phrase in any position in the searched text, good for words in different orders): analyzes input and consutructs a bool query from the terms. Each term EXCEPT the last is used in a term query. The last term is used in a prefix qery \n",
    "#match_phrase_prefix: matches its terms as a phrase \n",
    "\n",
    "#analyzer used by bool queries can be confiured with the analyzer paramter\n",
    "match_bool = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\n",
    "            'bool':{\n",
    "                \"should\":[\n",
    "                    {\"term\":{\"title\": \"nintendo\"}},\n",
    "                    {\"term\":{\"title\":\"launch\"}},\n",
    "                    {\"prefix\":{\"title\":\"ny\"}},\n",
    "                    \n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "#bool query with distance feature boosting \n",
    "#boosting results that are more recent \n",
    "match_bool_dist = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\n",
    "            'bool':{\n",
    "                \"must\":{\n",
    "                    \"match\":{\n",
    "                        \"title\":{\n",
    "                            \"query\":\"amazon\",\n",
    "                            \"fuzziness\":1\n",
    "                        }\n",
    "                    }\n",
    "                }, \n",
    "                \n",
    "                \"should\":{\n",
    "                    \"distance_feature\":{\n",
    "                        \"field\":\"date\",\n",
    "                        \"pivot\":\"10d\",\n",
    "                        \"origin\":\"now-1700d\"\n",
    "                    },\n",
    "              \n",
    "                }\n",
    "                    \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    " \n",
    "\n",
    "#analyzer used by bool queries can be confiured with the analyzer paramter\n",
    "#note:keyword analyzer very strict \n",
    "match_bool_analyze = es.search(\n",
    "    index='webhose',\n",
    "    body={\n",
    "        'query': {\n",
    "            'match_bool_prefix':{\n",
    "                \"title\":{\n",
    "                    \"query\":\"quick nintendo f\", \n",
    "                   # \"analyzer\":\"keyword\",\n",
    "                    \"fuzziness\":2,\n",
    "                }\n",
    "                \n",
    "            }\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "#show result\n",
    "mm_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most like this(MLT) query syntax\n",
    " - finds documents that are like a set of documents\n",
    " - 3 types of parameters \n",
    "     - document input \n",
    "     - term selection \n",
    "     - query formation \n",
    "\n",
    "#### Document Input Parameters \n",
    " - Like: ONLY required parameter of MLT query \n",
    "     - to provide documents not ncessarly present in index, **ARTIFICAL DOCUMENTS** are also supported \n",
    " - Unlike: exact opposite of like , tells search to return only info that is like something and not like something else \n",
    " - Fields: a list of fifelds to fetch and analyze the text from \n",
    " \n",
    "#### Term Selection Paramters \n",
    "- max_query_terms: max # of query terms to be selected\n",
    "    - Increasing this value gives greater accuracy at the expense of execution spped \n",
    "- min_term_freq: min doc freq below which the term will be ignored from the input doc (default 5)\n",
    "- min_doc_freq: the minimum doc freq below which the term is ignored (default 5) \n",
    "- max_doc_freq: max doc freq above which the term will be ignored, great for filtering out ocmmon words from input string(default infinity)\n",
    "- min_word_length: the min len below which a term is ignored \n",
    "- max_word_length: max len of word to be considred from input string \n",
    "- stop_words: an array of stopwords, any word in this set is dubbed 'uninteresting' and ignored\n",
    "\n",
    "#### Query Formation Parameters \n",
    " - minium_should_match : controls the number of terms that must match(defaults 30%)\n",
    " - fail_on_unsupported_field: specifies if the query should fail if any specified fields are not of the supported types(text or keyword). Defaults to TRUE.\n",
    "     - set to FALSE to ifnore the field and continue processing \n",
    " - boost_terms(default = 0): sets the boost factor to use based on terms tf-idf score. ANy positive value activates term boosting with the given booost factor \n",
    " - include(default = False): specifies weather the input docs should also be includeed in search results\n",
    " \n",
    "##### NOTE: Term Vectors API provides a good preprocess for MLT query "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "#return documents that are similar to a provdied peice of text (specified in 'like' query parameter)\n",
    "mlt_result1 = es.search(\n",
    "    index = 'webhose', \n",
    "    body = {\n",
    "            \"query\": {\n",
    "                \"more_like_this\" : {\n",
    "                    \"fields\" : [\"title\"],\n",
    "                    \"like\" : \"Amazon cloud failure\",\n",
    "                    \"min_term_freq\" : 1,\n",
    "                    \"min_doc_freq\": 1,\n",
    "                    \"max_query_terms\" : 24\n",
    "                }\n",
    "            }\n",
    "        }\n",
    ")\n",
    "\n",
    "#mixing texts with documents already existing in index (find docs similar to existing docs)\n",
    "#ex. find docs related to the existing doc with _id = ....\n",
    "mlt_result = es.search(\n",
    "    index = 'webhose', \n",
    "    body = {\n",
    "            \"query\": {\n",
    "                \"more_like_this\" : {\n",
    "                    \"fields\" : [\"title\", \"author\"],\n",
    "                    \"like\" : [\n",
    "                     {\n",
    "                         \"_index\":\"webhose\",\n",
    "                         \"_id\":\"aab7ad9ce6391f0e3da6c3ea69ba834f6b2ed4c90\"\n",
    "                     },\n",
    "                    ],\n",
    "                    \"min_term_freq\" : 1,\n",
    "                    \"max_query_terms\" : 12,\n",
    "                    \"include\":True,\n",
    "                    \"boost_terms\":.5,\n",
    "                    \"minimum_should_match\":\"30%\",\n",
    "                    \"stop_words\":['a','for','your']\n",
    "                }\n",
    "            }\n",
    "        }\n",
    ")\n",
    "\n",
    "#return documents that are similar to a provdied peice of text (specified in 'like' query parameter)\n",
    "mlt_result1 = es.search(\n",
    "    index = 'webhose', \n",
    "    body = {\n",
    "            \"query\": {\n",
    "                \"more_like_this\" : {\n",
    "                    \"fields\" : [\"title\"],\n",
    "                    \"like\" : [\"Amazon cloud failure\",\"s3\"],\n",
    "                    \"unlike\": \"free shipping\",\n",
    "                    \"stop_words\": ['a','the','is','then','could'],\n",
    "                    \"min_term_freq\" : 1,\n",
    "                    \"min_doc_freq\": 1,\n",
    "                    \"max_query_terms\" : 24,\n",
    "                    \"minimum_should_match\":\"20%\",\n",
    "                    \"fail_on_unsupported_field\":True,\n",
    "                    \"boost_terms\":.5,\n",
    "                }\n",
    "               \n",
    "            }\n",
    "        }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TERM VECTORS API \n",
    "\n",
    "##### three types of values(field and term information returned by default)\n",
    " - term information (always returned)\n",
    " - term statistics (positions=True)\n",
    " - field statistics (payloads = True) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.elastic.co/guide/en/elasticsearch/reference/7.4/docs-termvectors.html\n",
    "#return documents that are similar to a provdied peice of text (specified in 'like' query parameter)\n",
    "tv_result1 = es.termvectors(\n",
    "    index = 'webhose', \n",
    "    \n",
    "    body = {\n",
    "          \"fields\":[\"title\"],\n",
    "          \"_id\":\"aab7ad9ce6391f0e3da6c3ea69ba834f6b2ed4c90\",\n",
    "          \"term_statistics\":True    \n",
    "        }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CROSS FIELD MULTI MATCH QUERIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WARNING: I ONLY HAVE 3 FIELDS , SO I AM REDUNDENTLY SEARCHING TWO of THEM FOR illistration\n",
    "#https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl-minimum-should-match.html\n",
    "tv_result1 = es.search(\n",
    "    index = 'webhose', \n",
    "    \n",
    "    body = {\n",
    "    \n",
    "      \"query\": {\n",
    "        \"bool\": {\n",
    "          \"should\": [\n",
    "            #setting up 2 cross_field queries combined with a bool query, applying min_should_match parameter to one of them \n",
    "              #when using multiple queries, only apply min_should_match to one \n",
    "            {\n",
    "              \"multi_match\" : {\n",
    "                \"query\":      \"amazon outage\",\n",
    "                \"type\":       \"cross_fields\",\n",
    "                \"fields\":     [ \"author\", \"title\" ],\n",
    "                \"tie_breaker\": 1 , #instead of judging results based on single best score, add togetyher scores (across fields) for the query terms *not smart likley*\n",
    "                \"minimum_should_match\": \"50%\"        #1 of the two fields should contain the information \n",
    "              }\n",
    "            },\n",
    "            {\n",
    "              \"multi_match\" : {\n",
    "                \"query\":      \"amazon outage\",\n",
    "                \"type\":       \"cross_fields\",\n",
    "                \"fields\":     [ \"title\",\"author\" ],\n",
    "                \"tie_breaker\": 1 ,\n",
    "              }\n",
    "            }\n",
    "          ]\n",
    "        }\n",
    "      }\n",
    "    \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'took': 4,\n",
       " 'timed_out': False,\n",
       " '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0},\n",
       " 'hits': {'total': {'value': 10000, 'relation': 'gte'},\n",
       "  'max_score': 16.210983,\n",
       "  'hits': [{'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '14972b1121dbbb3a9b825679466cf905c69b1ef60',\n",
       "    '_score': 16.210983,\n",
       "    '_source': {'key': '14972b1121dbbb3a9b825679466cf905c69b1ef6',\n",
       "     'date': '2017-03-03T17:05:00.000+02:00',\n",
       "     'title': 'Amazon Outage Caused By Typo',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'dc88fc0b1732c21674e17603cdfb2401d3a98dee0',\n",
       "    '_score': 16.210983,\n",
       "    '_source': {'key': 'dc88fc0b1732c21674e17603cdfb2401d3a98dee',\n",
       "     'date': '2017-03-02T13:29:00.000+02:00',\n",
       "     'title': 'ISTEP spared by Amazon outage',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'ae347fff757f5297d0711cbead4a663c8944e25d0',\n",
       "    '_score': 16.210983,\n",
       "    '_source': {'key': 'ae347fff757f5297d0711cbead4a663c8944e25d',\n",
       "     'date': '2017-03-03T07:35:00.000+02:00',\n",
       "     'title': 'Typo caused outage, Amazon says',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '408567197b1d83d409905e1a0d037bce4a59e66d0',\n",
       "    '_score': 16.210983,\n",
       "    '_source': {'key': '408567197b1d83d409905e1a0d037bce4a59e66d',\n",
       "     'date': '2017-03-01T03:41:00.000+02:00',\n",
       "     'title': 'News: Amazon AWS S3 Outage',\n",
       "     'author': 'jermsmit'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '1d6e6b6a2d5d6538493d16dcbc4ca5a0a2653ad50',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': '1d6e6b6a2d5d6538493d16dcbc4ca5a0a2653ad5',\n",
       "     'date': '2017-03-03T03:47:00.000+02:00',\n",
       "     'title': 'Amazon: Human error caused the outage',\n",
       "     'author': 'jmosscrop'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '72f39034e77a02a98a0ff471e2a91bc61bc135cf0',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': '72f39034e77a02a98a0ff471e2a91bc61bc135cf',\n",
       "     'date': '2017-02-28T21:00:00.000+02:00',\n",
       "     'title': 'Amazon server outage hits huge companies',\n",
       "     'author': ''}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '492f55417c96d0b5cee4acba6e0c7bf1c4d520780',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': '492f55417c96d0b5cee4acba6e0c7bf1c4d52078',\n",
       "     'date': '2017-03-01T03:03:00.000+02:00',\n",
       "     'title': 'Amazon suffers partial cloud service outage',\n",
       "     'author': 'Reuters'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '190bd44ae300c59ac06bb9c97d82469da51e84d50',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': '190bd44ae300c59ac06bb9c97d82469da51e84d5',\n",
       "     'date': '2017-03-01T13:53:00.000+02:00',\n",
       "     'title': 'Amazon outage causes widespread internet problems',\n",
       "     'author': 'CBS News'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': 'c92da6dfc655eba9ddf34a48a933f0e0346a046b0',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': 'c92da6dfc655eba9ddf34a48a933f0e0346a046b',\n",
       "     'date': '2017-03-03T02:44:00.000+02:00',\n",
       "     'title': 'Amazon outage due to human error',\n",
       "     'author': 'Washington Post'}},\n",
       "   {'_index': 'webhose',\n",
       "    '_type': '_doc',\n",
       "    '_id': '9f2ab9af805dbd78d0f7e3378a094cfc390e33590',\n",
       "    '_score': 15.430631,\n",
       "    '_source': {'key': '9f2ab9af805dbd78d0f7e3378a094cfc390e3359',\n",
       "     'date': '2017-03-03T03:31:00.000+02:00',\n",
       "     'title': 'Amazon explains massive cloud-computing outage',\n",
       "     'author': 'New York City Informer'}}]}}"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tv_result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
