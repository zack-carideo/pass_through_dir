{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Snappy implementation of Min Hash with LSH "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapy import MinHash, LSH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinHash function Parameters\n",
    " - **text:** list of strings containing texts to compare \n",
    " - **n_gram:** size of each overlapping text shingle to break text into prior to hashing \n",
    "  - value should be selected based on avg text length \n",
    "   - to low shingle size-> false similarities \n",
    "   - to high shingle size-> fail to return true positives \n",
    " - **n_gram_type:** type of ngram to use for shingles(char or term) \n",
    "  - **char** splits text into character shingles\n",
    "  - **term** splits text into overlapping sequences of words \n",
    "\n",
    " - **permutations:** number of randomly sampled hash values to use for generating each texts minhash signature. the larger this is , the more accruate jaccard similarities between texts will be , but at cost of efficency\n",
    " - **hash_bits:** hash value size to be used to generate minhash signitures from shingles (32,64, or 128 bit). \n",
    "  - should be chosen based on text length and a trade off between performance ad accuracy \n",
    "  - **lower** hash values risk fals hash collisions leading to false similiarities between docs for larger corpuses\n",
    " - **method:** method for randomly sampling via hashing \n",
    "  - **multi_hash** texts are hashed once per permutation and the min hash value selected each time to construct signature(STABLE)\n",
    "  - **k_smallest_values** each text is hashed once and k smallest values selected for k permutations (NOT STABLE) \n",
    " - **seed:** seed from which to generate random hash function, necessary for reproducivibility and to allow updating of the LSH model with new minihash values. \n",
    "\n",
    "## LSH Function Parameters \n",
    "##### lsh (local sensativity hashing) creates a model of text similarity that can be used to return similar texts based on estimated jaccard similaritiy\n",
    " - **minhash:** Minhash object containing minhash signatures return by MinHash Class\n",
    " - **labels:** list, array, or series containing unique labels for each text in minhash object signiture. This should be provided in the same order as texts passed to the MinHash class. \n",
    " - **no_of_bands:** number of bands to break minhash signature into before hashing into buckets \n",
    "  - **smaller** number of bands will result in a stricter algo (risk of false negatives ) \n",
    "  - **larger** risk of false positives\n",
    "\n",
    "## LSH Methods \n",
    " - **update:** updtes a model from a Minhash object containing signitures generated from new texts and their labels \n",
    "  - .update(minhash,new_labels)\n",
    " - **query:** takes a label and returns the labels of similar texts (sensativity = # buckets text must share to be returned as similar) \n",
    "  - .query(label,min_jaccard=None, sensitivity = 1)\n",
    " \n",
    " - **remove:** remove file label andminhash signiture from model \n",
    "  - .def remove(label):\n",
    " \n",
    " - **contains:** returns list of labels contained in the model \n",
    "  - .contains()\n",
    " \n",
    " - **adjancency_list:** returns an adjacency list that can be used to create a **text similarity graph**\n",
    " \n",
    " - **edge_list:** returns a list of edges as tples of similar paris, that can be used to create a **text similarity graph**\n",
    "  - .edge_list(min_jaccard= None, jaccard_weighted=False, sensativity = 1) \n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test list of strings to run exmaple\n",
    "content = [\n",
    "    'Jupiter is primarily composed of hydrogen with a quarter of its mass being helium',\n",
    "    'Jupiter moving out of the inner Solar System would have allowed the formation of inner planets.',\n",
    "    'A helium atom has about four times as much mass as a hydrogen atom, so the composition changes when described as the proportion of mass contributed by different atoms.',\n",
    "    'Jupiter is primarily composed of hydrogen and a quarter of its mass being helium',\n",
    "    'A helium atom has about four times as much mass as a hydrogen atom and '\n",
    "    'the composition changes when described as a proportion of mass contributed by different atoms.',\n",
    "    'Theoretical models indicate that if Jupiter had much more mass than it does at present, it would shrink.',\n",
    "    'This process causes Jupiter to shrink by about 2 cm each year.',\n",
    "    'Jupiter is mostly composed of hydrogen with a quarter of its mass being helium',\n",
    "    'The Great Red Spot is large enough to accommodate Earth within its boundaries.'\n",
    "]\n",
    "\n",
    "#set of default lables for each string beng evaluted\n",
    "labels = [1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "#seed to enable replication \n",
    "seed = 3\n",
    "\n",
    "#size of each overlapping text shingle to break text into prior to hashing\n",
    "n_gram = 9\n",
    "\n",
    "#number of randomly sampled hash values to use for generating each texts minhash signature (larger = more accurate & slower)\n",
    "permutations=100\n",
    "\n",
    "#hash value size to be used to generate minhash signitures from shingles (32,64, or 128 bit). \n",
    "#NOTE: should be chosen based on text length and a trade off between performance ad accuracy\n",
    "hash_bits = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create MinHash object.\n",
    "minhash = MinHash(content, n_gram=n_gram, permutations=permutations, hash_bits=hash_bits, seed=seed)\n",
    "\n",
    "# Create LSH model.\n",
    "lsh = LSH(minhash, labels, no_of_bands=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations (querying for similar docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 4]\n"
     ]
    }
   ],
   "source": [
    "#query to find near duplicates for text 1 \n",
    "print(lsh.query(1,min_jaccard=.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Updating(add new documents to lsh model)\n",
    " 1. Create minhash signitures for each new document \n",
    " 2. update existing lsh model with new has signitures and labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate minhash aignitures for new text, and add new texts to LSH model \n",
    "new_text = [\n",
    "    'Jupiter is primarily composed of hydrogen with a quarter of its mass being helium',\n",
    "    'Jupiter moving out of the inner Solar System would have allowed the formation of inner planets.',\n",
    "]\n",
    "\n",
    "new_labels =['new_doc1','new_doc2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.create minhash signitues for new text \n",
    "new_minhash = MinHash(new_text, n_gram=n_gram, permutations=permutations, hash_bits=hash_bits, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 'new_doc1', 'new_doc2']\n"
     ]
    }
   ],
   "source": [
    "#2.update lsh model with new hash signitures and verify lsh model updates reflected\n",
    "lsh.update(new_minhash,new_labels)\n",
    "print(lsh.contains())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### General operations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: [8, 'new_doc1', 4], 2: ['new_doc2'], 3: [5], 4: [1, 8, 'new_doc1'], 5: [3], 6: [], 7: [], 8: [1, 'new_doc1', 4], 9: [], 'new_doc1': [1, 8, 4], 'new_doc2': [2]}\n",
      "[('new_doc2', 2), ('new_doc1', 1), ('new_doc1', 8), ('new_doc1', 4), (8, 1), (8, 4), (5, 3), (4, 1)]\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 'new_doc1', 'new_doc2']\n"
     ]
    }
   ],
   "source": [
    "#print the adjacency_list of all docs \n",
    "print(lsh.adjacency_list())\n",
    "\n",
    "#print the edge list of all docs that are flagged as duplicates to plot in text similarity graph \n",
    "print(lsh.edge_list())\n",
    "\n",
    "#remove text and label from model (if its not there , you will get an error returned)\n",
    "lsh.remove(6)\n",
    "print(lsh.contains())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting matrix of text signatures from minhash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 100)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get matrix(n*m) of text signatures generated by minhash function (n=text row, m=selected permutations)\n",
    "minhash.signatures.shape "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
